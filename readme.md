**ğŸ“˜ Generation AugmentÃ©e par RÃ©cupÃ©ration (RAG Correctif)**

ImplÃ©mentation complÃ¨te dâ€™un RAG (Retrieval-Augmented Generation) avec une boucle corrective (CRAG) permettant dâ€™amÃ©liorer la pertinence des rÃ©ponses gÃ©nÃ©rÃ©es par un modÃ¨le de langage.


Ce projet dÃ©montre comment :

->Indexer un corpus

->Effectuer une recherche sÃ©mantique vectorielle

->Filtrer les documents non pertinents

->Reformuler automatiquement la requÃªte si nÃ©cessaire

->GÃ©nÃ©rer une rÃ©ponse finale basÃ©e uniquement sur un contexte fiable

**Qu'est-ce que le RAG Correctif ?**

Le RAG Correctif (CRAG) amÃ©liore le RAG en vÃ©rifiant et corrigeant lâ€™Ã©tape de rÃ©cupÃ©ration avant la gÃ©nÃ©ration.

Le process :

RÃ©cupÃ©rer les documents â†’ RÃ©cupÃ©rer les chunks candidats.

Noter la pertinence â†’ Ã‰valuer si chaque document est vraiment liÃ© Ã  la question de lâ€™utilisateur.

Filtrer â†’ Garder uniquement les documents pertinents, Ã©liminer les non pertinents.

Corriger la query â†’ Si aucun bon document nâ€™est trouvÃ©, rÃ©Ã©crire la query et rÃ©essayer la rÃ©cupÃ©ration.

GÃ©nÃ©rer la rÃ©ponse â†’ Utiliser uniquement les documents fiables et pertinents pour la rÃ©ponse finale.

**Analogie:**
RAG classique : Vous posez une question Ã  un ami, il vous apporte une pile de livres qui pourraient aider, et il essaie de rÃ©pondre immÃ©diatement.

RAG Correctif : Lâ€™ami parcourt les livres, Ã©limine ceux qui ne sont pas pertinents, et si aucun nâ€™est utile, il reformule votre question et cherche Ã  nouveau. Ce nâ€™est quâ€™ensuite quâ€™il rÃ©pond.

**Avantages**

RÃ©duit les hallucinations en Ã©liminant le contexte non pertinent.

Produit des rÃ©ponses plus prÃ©cises et dignes de confiance.

Ajoute de la robustesse car il peut rÃ©essayer si la premiÃ¨re tentative de rÃ©cupÃ©ration Ã©choue.

**Point clÃ©**

RAG Correctif = RAG + une boucle de filtrage et de correction.
Il rend la rÃ©cupÃ©ration plus intelligente et plus fiable en validant les documents et en affinant les queries avant de gÃ©nÃ©rer la rÃ©ponse finale.



Generation-augmente-par-recuperation/
â”‚
â”œâ”€â”€Diagrammes/
â”‚   â”œâ”€â”€ DIAGRAMME_SEQUENCE.png
â”‚   â”œâ”€â”€ RAG correctif â€“ diagramme d'activitÃ©.png
â”œâ”€â”€Fichiers pdf/
â”‚   â”œâ”€â”€ atos-retrieval-augmented-generation-ai-whitepaper.pdf
â”‚   â”œâ”€â”€ Corrective_Retrieval_Augm.pdf
â”‚   â”œâ”€â”€ IA_et_Transformation digitale.pdf
â”‚   â”œâ”€â”€ Tabular_list_of_deseases.py
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”œâ”€â”€ chunking.py
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ retrieval.py
â”‚   â”œâ”€â”€ grader.py
â”‚   â”œâ”€â”€ query_transform.py
â”‚   â””â”€â”€ pipeline.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ generation_model.py
â”‚   â””â”€â”€ model_config.py
â”‚
â”œâ”€â”€ Test/
â”‚   â””â”€â”€ Test_rag_correctif.py
â”‚
â””â”€â”€ requirements.txt



âš™ï¸ Fonctionnement du pipeline

1ï¸âƒ£ Chargement des documents
2ï¸âƒ£ DÃ©coupage en chunks
3ï¸âƒ£ GÃ©nÃ©ration des embeddings
4ï¸âƒ£ Indexation dans FAISS
5ï¸âƒ£ Recherche sÃ©mantique
6ï¸âƒ£ Filtrage des documents non pertinents
7ï¸âƒ£ Reformulation si aucun bon document
8ï¸âƒ£ GÃ©nÃ©ration finale via LLM

![alt text](<Diagrammes/RAG correctif â€“ diagramme d'activitÃ©.png>)


ğŸš€ Installation

git clone https://github.com/Yobapatrick/Generation-augmente-par-recuperation.git
cd Generation-augmente-par-recuperation

python -m venv venv
source venv/bin/activate   # Windows : venv\Scripts\activate

pip install -r requirements.txt

python TEST/Test_rag_correctif.py


â­ Auteur
Patrick Yoba
Ã‰tudiant ingÃ©nieur 3IL INGENIEURS â€“ Data & IA
PassionnÃ© par les architectures LLM, RAG et systÃ¨mes intelligents.